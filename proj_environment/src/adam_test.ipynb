{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filer i ZIP: ['soil_data.csv', 'test_timeseries/test_timeseries.csv', 'train_timeseries/train_timeseries.csv', 'validation_timeseries/validation_timeseries.csv']\n",
      "Kolonnenavn: Index(['fips', 'date', 'PRECTOT', 'PS', 'QV2M', 'T2M', 'T2MDEW', 'T2MWET',\n",
      "       'T2M_MAX', 'T2M_MIN', 'T2M_RANGE', 'TS', 'WS10M', 'WS10M_MAX',\n",
      "       'WS10M_MIN', 'WS10M_RANGE', 'WS50M', 'WS50M_MAX', 'WS50M_MIN',\n",
      "       'WS50M_RANGE', 'score'],\n",
      "      dtype='object')\n",
      "Antall rader: 0\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://www.kaggle.com/api/v1/datasets/download/cdminix/us-drought-meteorological-data\"\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "zip_file = zipfile.ZipFile(io.BytesIO(response.content))\n",
    "\n",
    "print(\"Filer i ZIP:\", zip_file.namelist())\n",
    "\n",
    "csv_filename = zip_file.namelist()[1]  \n",
    "\n",
    "# Hent ut bare info om dataene uten å laste hele filen\n",
    "with zip_file.open(csv_filename) as csv_file:\n",
    "    # Bruk pandas read_csv med parameteren `nrows` for å hente kun en liten del\n",
    "    df = pd.read_csv(csv_file, nrows=0)  # Henter kun headeren\n",
    "    \n",
    "# Vis kolonnenavn og antall rader\n",
    "print(\"Kolonnenavn:\", df.columns)\n",
    "print(\"Antall rader:\", len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filer i ZIP: ['soil_data.csv', 'test_timeseries/test_timeseries.csv', 'train_timeseries/train_timeseries.csv', 'validation_timeseries/validation_timeseries.csv']\n",
      "Kolonner: Index(['fips', 'date', 'PRECTOT', 'PS', 'QV2M', 'T2M', 'T2MDEW', 'T2MWET',\n",
      "       'T2M_MAX', 'T2M_MIN', 'T2M_RANGE', 'TS', 'WS10M', 'WS10M_MAX',\n",
      "       'WS10M_MIN', 'WS10M_RANGE', 'WS50M', 'WS50M_MAX', 'WS50M_MIN',\n",
      "       'WS50M_RANGE', 'score'],\n",
      "      dtype='object')\n",
      "Antall rader: 2271948\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "import pandas as pd\n",
    "import pandasql as psql\n",
    "\n",
    "url = \"https://www.kaggle.com/api/v1/datasets/download/cdminix/us-drought-meteorological-data\"\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "zip_file = zipfile.ZipFile(io.BytesIO(response.content))\n",
    "\n",
    "print(\"Filer i ZIP:\", zip_file.namelist())\n",
    "\n",
    "csv_filename = zip_file.namelist()[1]  \n",
    "\n",
    "# Les inn CSV-filen som vanlig\n",
    "with zip_file.open(csv_filename) as csv_file:\n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "# Bruk pandasql for SQL-lignende spørringer\n",
    "query = \"SELECT * FROM df LIMIT 0\"  # Henter kun headeren, ingen data\n",
    "metadata = psql.sqldf(query, locals())\n",
    "\n",
    "# Skriv ut kolonner og antall rader\n",
    "print(\"Kolonner:\", metadata.columns)\n",
    "print(\"Antall rader:\", len(df))\n",
    "\n",
    "#Korrekt kode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'train_timeseries.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m csv_filename = \u001b[33m'\u001b[39m\u001b[33mtrain_timeseries.csv\u001b[39m\u001b[33m'\u001b[39m  \u001b[38;5;66;03m# Lokasjonen til din fil på datamaskinen\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Les hele CSV-filen\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_filename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Bruk pandasql for SQL-lignende spørringer\u001b[39;00m\n\u001b[32m     11\u001b[39m query = \u001b[33m\"\u001b[39m\u001b[33mSELECT * FROM df LIMIT 0\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# Henter kun headeren, ingen data\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Adam\\Anvendt Programmering\\Ramsey_Del1\\Ramsey-1\\proj_environment\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Adam\\Anvendt Programmering\\Ramsey_Del1\\Ramsey-1\\proj_environment\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Adam\\Anvendt Programmering\\Ramsey_Del1\\Ramsey-1\\proj_environment\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Adam\\Anvendt Programmering\\Ramsey_Del1\\Ramsey-1\\proj_environment\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Adam\\Anvendt Programmering\\Ramsey_Del1\\Ramsey-1\\proj_environment\\.venv\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'train_timeseries.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pandasql as psql\n",
    "\n",
    "# Les CSV-filen direkte fra din lokale fil\n",
    "csv_filename = 'train_timeseries.csv'  # Lokasjonen til din fil på datamaskinen\n",
    "\n",
    "# Les hele CSV-filen\n",
    "df = pd.read_csv(csv_filename)\n",
    "\n",
    "# Bruk pandasql for SQL-lignende spørringer\n",
    "query = \"SELECT * FROM df LIMIT 0\"  # Henter kun headeren, ingen data\n",
    "metadata = psql.sqldf(query, locals())\n",
    "\n",
    "# Skriv ut kolonner og antall rader\n",
    "print(\"Kolonner:\", metadata.columns)\n",
    "print(\"Antall rader:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filer i ZIP: ['soil_data.csv', 'test_timeseries/test_timeseries.csv', 'train_timeseries/train_timeseries.csv', 'validation_timeseries/validation_timeseries.csv']\n",
      "   fips        date  PRECTOT      PS  QV2M    T2M  T2MDEW  T2MWET  T2M_MAX  \\\n",
      "0  1001  2019-01-01     2.25  100.51  9.69  14.71   13.55   13.52    17.38   \n",
      "1  1001  2019-01-02     4.94  100.48  8.65  13.05   11.83   11.74    17.76   \n",
      "2  1001  2019-01-03    20.74  100.03  8.59  12.12   11.67   11.67    13.74   \n",
      "3  1001  2019-01-04    16.17   99.47  7.93  11.80   10.38    9.59    18.19   \n",
      "4  1001  2019-01-05     0.01  100.39  5.32   7.91    4.73    4.71    14.37   \n",
      "\n",
      "   T2M_MIN  ...     TS  WS10M  WS10M_MAX  WS10M_MIN  WS10M_RANGE  WS50M  \\\n",
      "0    10.92  ...  14.63   1.20       1.50       0.79         0.71   2.74   \n",
      "1     9.54  ...  13.06   1.02       1.35       0.32         1.03   2.13   \n",
      "2    10.44  ...  12.12   1.83       4.23       0.34         3.88   3.41   \n",
      "3     5.44  ...  11.72   3.75       5.25       2.34         2.91   6.78   \n",
      "4     3.68  ...   7.75   2.32       2.90       1.69         1.21   4.42   \n",
      "\n",
      "   WS50M_MAX  WS50M_MIN  WS50M_RANGE  score  \n",
      "0       4.01       1.23         2.78    0.0  \n",
      "1       3.37       0.56         2.81    NaN  \n",
      "2       7.49       0.72         6.77    NaN  \n",
      "3       9.61       4.90         4.71    NaN  \n",
      "4       5.87       3.15         2.72    NaN  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "Kolonner: Index(['fips', 'date', 'PRECTOT', 'PS', 'QV2M', 'T2M', 'T2MDEW', 'T2MWET',\n",
      "       'T2M_MAX', 'T2M_MIN', 'T2M_RANGE', 'TS', 'WS10M', 'WS10M_MAX',\n",
      "       'WS10M_MIN', 'WS10M_RANGE', 'WS50M', 'WS50M_MAX', 'WS50M_MIN',\n",
      "       'WS50M_RANGE', 'score'],\n",
      "      dtype='object')\n",
      "Antall rader: 2271948\n",
      "Forventet antall rader: 5840\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "import pandas as pd\n",
    "import pandasql as psql\n",
    "\n",
    "url = \"https://www.kaggle.com/api/v1/datasets/download/cdminix/us-drought-meteorological-data\"\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "# Åpne ZIP-filen og sjekk innholdet\n",
    "zip_file = zipfile.ZipFile(io.BytesIO(response.content))\n",
    "print(\"Filer i ZIP:\", zip_file.namelist())\n",
    "\n",
    "# Hent filnavn fra ZIP (antar at det er CSV filen på den andre indeksen)\n",
    "csv_filename = zip_file.namelist()[1]  \n",
    "\n",
    "# Sjekk de første radene for å få oversikt over strukturen\n",
    "with zip_file.open(csv_filename) as csv_file:\n",
    "    df_preview = pd.read_csv(csv_file, nrows=5)  # Kun de første 5 radene for å inspisere\n",
    "print(df_preview)\n",
    "\n",
    "# Hvis du har en veldig stor fil, kan du bruke chunksize for å lese den i biter\n",
    "# Bestem hvilke kolonner og datatyper du trenger\n",
    "dtype = {\n",
    "    'column1': 'str',  # Endre til relevante kolonner og datatyper\n",
    "    'column2': 'float',\n",
    "    # ... spesifiser flere kolonner etter behov\n",
    "}\n",
    "\n",
    "# Bruk chunksize for å lese inn data i biter\n",
    "chunk_size = 100000  # Juster etter hva som passer for minnet ditt\n",
    "chunks = []\n",
    "with zip_file.open(csv_filename) as csv_file:\n",
    "    for chunk in pd.read_csv(csv_file, chunksize=chunk_size, dtype=dtype):\n",
    "        chunks.append(chunk)\n",
    "\n",
    "# Slå sammen alle bitene\n",
    "df = pd.concat(chunks, axis=0)\n",
    "\n",
    "# Bruk pandasql for SQL-lignende spørringer\n",
    "query = \"SELECT * FROM df LIMIT 0\"  # Henter kun headeren\n",
    "metadata = psql.sqldf(query, locals())\n",
    "\n",
    "# Skriv ut kolonner og antall rader\n",
    "print(\"Kolonner:\", metadata.columns)\n",
    "print(\"Antall rader:\", len(df))\n",
    "\n",
    "# Hvis du forventer 16*365 rader (16 år, 365 dager per år), kan du kontrollere om antall rader er korrekt\n",
    "expected_rows = 16 * 365\n",
    "print(f\"Forventet antall rader: {expected_rows}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filer i ZIP: ['soil_data.csv', 'test_timeseries/test_timeseries.csv', 'train_timeseries/train_timeseries.csv', 'validation_timeseries/validation_timeseries.csv']\n",
      "Første 5 rader:    fips        date  PRECTOT      PS  QV2M    T2M  T2MDEW  T2MWET  T2M_MAX  \\\n",
      "0  1001  2019-01-01     2.25  100.51  9.69  14.71   13.55   13.52    17.38   \n",
      "1  1001  2019-01-02     4.94  100.48  8.65  13.05   11.83   11.74    17.76   \n",
      "2  1001  2019-01-03    20.74  100.03  8.59  12.12   11.67   11.67    13.74   \n",
      "3  1001  2019-01-04    16.17   99.47  7.93  11.80   10.38    9.59    18.19   \n",
      "4  1001  2019-01-05     0.01  100.39  5.32   7.91    4.73    4.71    14.37   \n",
      "\n",
      "   T2M_MIN  ...     TS  WS10M  WS10M_MAX  WS10M_MIN  WS10M_RANGE  WS50M  \\\n",
      "0    10.92  ...  14.63   1.20       1.50       0.79         0.71   2.74   \n",
      "1     9.54  ...  13.06   1.02       1.35       0.32         1.03   2.13   \n",
      "2    10.44  ...  12.12   1.83       4.23       0.34         3.88   3.41   \n",
      "3     5.44  ...  11.72   3.75       5.25       2.34         2.91   6.78   \n",
      "4     3.68  ...   7.75   2.32       2.90       1.69         1.21   4.42   \n",
      "\n",
      "   WS50M_MAX  WS50M_MIN  WS50M_RANGE  score  \n",
      "0       4.01       1.23         2.78    0.0  \n",
      "1       3.37       0.56         2.81    NaN  \n",
      "2       7.49       0.72         6.77    NaN  \n",
      "3       9.61       4.90         4.71    NaN  \n",
      "4       5.87       3.15         2.72    NaN  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "Siste 5 rader:           fips        date  PRECTOT     PS  QV2M   T2M  T2MDEW  T2MWET  \\\n",
      "2271943  56043  2020-12-27     3.83  82.91  2.77 -3.61   -6.77   -5.19   \n",
      "2271944  56043  2020-12-28     0.00  83.04  1.82 -7.31  -12.06   -9.68   \n",
      "2271945  56043  2020-12-29     0.00  82.78  1.87 -7.38  -11.79   -9.59   \n",
      "2271946  56043  2020-12-30     0.01  82.87  1.57 -6.40  -13.94  -10.17   \n",
      "2271947  56043  2020-12-31     0.00  82.82  2.13 -3.83  -10.12   -6.98   \n",
      "\n",
      "         T2M_MAX  T2M_MIN  ...     TS  WS10M  WS10M_MAX  WS10M_MIN  \\\n",
      "2271943     0.24    -9.07  ...  -5.88   2.98       6.04       0.72   \n",
      "2271944    -1.48   -11.51  ... -10.61   1.83       2.81       0.10   \n",
      "2271945    -0.88   -11.39  ... -10.81   2.70       6.22       0.18   \n",
      "2271946     1.33   -12.16  ...  -8.74   2.93       4.10       1.62   \n",
      "2271947     2.16    -8.57  ...  -6.61   2.16       3.72       0.31   \n",
      "\n",
      "         WS10M_RANGE  WS50M  WS50M_MAX  WS50M_MIN  WS50M_RANGE   score  \n",
      "2271943         5.31   4.56       7.68       1.03         6.66     NaN  \n",
      "2271944         2.72   2.52       3.69       0.14         3.56     NaN  \n",
      "2271945         6.04   3.84       7.66       0.29         7.37  3.5182  \n",
      "2271946         2.48   4.42       6.05       2.79         3.26     NaN  \n",
      "2271947         3.41   3.39       6.46       0.41         6.06     NaN  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "import pandas as pd\n",
    "\n",
    "# URL for å laste ned datasettet\n",
    "url = \"https://www.kaggle.com/api/v1/datasets/download/cdminix/us-drought-meteorological-data\"\n",
    "\n",
    "# Send HTTP forespørsel for å laste ned ZIP-filen\n",
    "response = requests.get(url)\n",
    "\n",
    "# Åpne ZIP-filen og sjekk innholdet\n",
    "zip_file = zipfile.ZipFile(io.BytesIO(response.content))\n",
    "print(\"Filer i ZIP:\", zip_file.namelist())\n",
    "\n",
    "# Hent filnavn fra ZIP (velg en av CSV-filene)\n",
    "csv_filename = zip_file.namelist()[1]  # Her antar vi at den første filen er den relevante CSV-filen\n",
    "\n",
    "# Les hele CSV-filen og vis de første 5 radene\n",
    "with zip_file.open(csv_filename) as csv_file:\n",
    "    df = pd.read_csv(csv_file)  # Les hele filen\n",
    "    df_preview = df.head(5)  # Første 5 rader\n",
    "    print(\"Første 5 rader:\", df_preview)\n",
    "\n",
    "    # Hent de siste 5 radene\n",
    "    df_tail = df.tail(5)  # Siste 5 rader\n",
    "    print(\"Siste 5 rader:\", df_tail)\n",
    "\n",
    "# Hvis du vil prosessere data i biter for å håndtere store filer, kan du bruke chunksize\n",
    "# Eksempel: Behandle filen i biter på 100,000 rader (juster etter behov)\n",
    "chunksize = 100000\n",
    "chunks = pd.read_csv(zip_file.open(csv_filename), chunksize=chunksize)\n",
    "\n",
    "# Her kan du bearbeide hver chunk hvis du ønsker å gjøre noe med dataene, f.eks. slå sammen eller analysere\n",
    "for chunk in chunks:\n",
    "    # Eksempel: Legg til behandlingen av hver chunk her, som å filtrere, analysere eller legge til data i en ny DataFrame\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filer i ZIP: ['soil_data.csv', 'test_timeseries/test_timeseries.csv', 'train_timeseries/train_timeseries.csv', 'validation_timeseries/validation_timeseries.csv']\n",
      "Antall duplikater i DataFrame: 0\n",
      "Antall rader uten duplikater: 2271948\n",
      "Antall duplikater basert på kolonnene 'fips' og 'date': 0\n",
      "Duplikate rader funnet via SQL:\n",
      " Empty DataFrame\n",
      "Columns: [fips, date, COUNT(*)]\n",
      "Index: []\n",
      "Antall rader etter fjerning av duplikater: 2271948\n",
      "En tilfeldig rad fra datasettet:\n",
      "         fips        date  PRECTOT     PS  QV2M   T2M  T2MDEW  T2MWET  \\\n",
      "904548  26081  2019-10-29     1.19  99.16  4.44  4.36    1.96    1.89   \n",
      "\n",
      "        T2M_MAX  T2M_MIN  ...    TS  WS10M  WS10M_MAX  WS10M_MIN  WS10M_RANGE  \\\n",
      "904548     7.57     0.43  ...  4.99   3.96       5.64       2.37         3.27   \n",
      "\n",
      "        WS50M  WS50M_MAX  WS50M_MIN  WS50M_RANGE  score  \n",
      "904548   5.39       7.07       3.88         3.19    0.0  \n",
      "\n",
      "[1 rows x 21 columns]\n",
      "Rad på index 100000:\n",
      "fips                 5109\n",
      "date           2020-08-07\n",
      "PRECTOT              2.51\n",
      "PS                  99.25\n",
      "QV2M                15.68\n",
      "T2M                 25.31\n",
      "T2MDEW              21.02\n",
      "T2MWET              20.89\n",
      "T2M_MAX              31.6\n",
      "T2M_MIN             19.75\n",
      "T2M_RANGE           11.86\n",
      "TS                  25.28\n",
      "WS10M                 1.4\n",
      "WS10M_MAX            2.06\n",
      "WS10M_MIN            0.71\n",
      "WS10M_RANGE          1.35\n",
      "WS50M                3.21\n",
      "WS50M_MAX            5.17\n",
      "WS50M_MIN            1.05\n",
      "WS50M_RANGE          4.12\n",
      "score                 NaN\n",
      "Name: 100000, dtype: object\n",
      "Rad nær midten av datasettet (index 1135974):\n",
      "fips                29213\n",
      "date           2019-01-01\n",
      "PRECTOT              0.02\n",
      "PS                  98.13\n",
      "QV2M                 3.14\n",
      "T2M                 -0.47\n",
      "T2MDEW              -2.92\n",
      "T2MWET              -2.88\n",
      "T2M_MAX              3.32\n",
      "T2M_MIN             -3.06\n",
      "T2M_RANGE            6.38\n",
      "TS                  -0.06\n",
      "WS10M                2.72\n",
      "WS10M_MAX            3.87\n",
      "WS10M_MIN             1.5\n",
      "WS10M_RANGE          2.37\n",
      "WS50M                4.12\n",
      "WS50M_MAX            5.66\n",
      "WS50M_MIN            2.58\n",
      "WS50M_RANGE          3.08\n",
      "score                 0.0\n",
      "Name: 1135974, dtype: object\n",
      "Rader rundt midten av datasettet:\n",
      "          fips        date  PRECTOT     PS  QV2M    T2M  T2MDEW  T2MWET  \\\n",
      "1135964  29211  2020-12-22     0.00  98.25  3.83   3.06   -0.17    1.45   \n",
      "1135965  29211  2020-12-23     0.30  97.02  3.98   2.09    0.15    1.12   \n",
      "1135966  29211  2020-12-24     0.00  98.38  0.99 -10.20  -17.44  -13.82   \n",
      "1135967  29211  2020-12-25     0.00  98.53  1.51  -9.00  -12.25  -10.63   \n",
      "1135968  29211  2020-12-26     0.14  97.97  3.20  -1.28   -2.67   -1.97   \n",
      "1135969  29211  2020-12-27     0.55  97.60  3.84   0.75   -0.27    0.24   \n",
      "1135970  29211  2020-12-28     0.03  99.48  2.20  -3.90   -7.37   -5.64   \n",
      "1135971  29211  2020-12-29    31.29  98.86  2.80  -2.93   -4.37   -3.65   \n",
      "1135972  29211  2020-12-30     0.82  98.51  2.47  -5.20   -6.06   -5.63   \n",
      "1135973  29211  2020-12-31     0.13  99.02  1.67 -10.09  -10.97  -10.53   \n",
      "1135974  29213  2019-01-01     0.02  98.13  3.14  -0.47   -2.92   -2.88   \n",
      "1135975  29213  2019-01-02     0.57  97.93  3.01  -1.80   -3.51   -3.39   \n",
      "1135976  29213  2019-01-03     1.47  97.35  3.29   0.17   -2.40   -2.39   \n",
      "1135977  29213  2019-01-04    27.79  96.77  3.77   0.98   -0.63   -0.60   \n",
      "1135978  29213  2019-01-05     0.05  97.40  4.63   3.54    2.29    1.94   \n",
      "1135979  29213  2019-01-06     0.00  97.26  6.48   7.79    7.08    6.92   \n",
      "1135980  29213  2019-01-07     0.07  96.86  8.09  11.80   10.28   10.25   \n",
      "1135981  29213  2019-01-08     0.00  97.96  4.57   5.87    2.24    2.00   \n",
      "1135982  29213  2019-01-09     0.00  98.65  2.61  -0.68   -5.23   -5.07   \n",
      "1135983  29213  2019-01-10     0.99  98.27  2.90  -0.11   -3.91   -3.91   \n",
      "\n",
      "         T2M_MAX  T2M_MIN  ...     TS  WS10M  WS10M_MAX  WS10M_MIN  \\\n",
      "1135964     8.95    -2.07  ...   1.92   5.85       9.20       1.61   \n",
      "1135965    10.93    -7.98  ...   1.78  11.79      13.15       9.41   \n",
      "1135966    -7.41   -14.00  ...  -9.53   8.32      11.07       4.97   \n",
      "1135967    -2.57   -15.06  ...  -8.58   4.53       5.59       3.68   \n",
      "1135968     4.63    -5.05  ...  -1.11   3.26       5.43       0.48   \n",
      "1135969     3.96    -1.90  ...   0.43   5.49       7.55       3.58   \n",
      "1135970    -0.96    -5.72  ...  -3.64   4.05       6.99       1.60   \n",
      "1135971     0.15    -5.34  ...  -2.94   5.65      11.37       1.69   \n",
      "1135972     0.09   -13.27  ...  -6.26   5.06       8.38       2.94   \n",
      "1135973    -3.56   -14.30  ... -11.31   2.53       5.06       0.14   \n",
      "1135974     3.32    -3.06  ...  -0.06   2.72       3.87       1.50   \n",
      "1135975    -0.48    -2.90  ...  -1.57   1.63       2.51       1.00   \n",
      "1135976     3.93    -2.80  ...   0.13   1.54       2.75       0.62   \n",
      "1135977     5.33    -1.65  ...   0.65   2.89       3.46       2.13   \n",
      "1135978    12.70    -2.39  ...   2.46   2.65       3.13       1.77   \n",
      "1135979    12.82     3.01  ...   7.12   3.55       5.03       2.58   \n",
      "1135980    16.98     6.62  ...  11.21   4.78       7.05       2.56   \n",
      "1135981    10.31     0.27  ...   5.50   3.94       5.56       2.64   \n",
      "1135982     4.24    -3.95  ...  -0.74   3.59       5.96       2.09   \n",
      "1135983     5.29    -4.38  ...  -0.14   2.07       2.80       1.54   \n",
      "\n",
      "         WS10M_RANGE  WS50M  WS50M_MAX  WS50M_MIN  WS50M_RANGE  score  \n",
      "1135964         7.58   8.77      13.25       2.38        10.86    1.0  \n",
      "1135965         3.74  15.36      17.99      13.59         4.39    NaN  \n",
      "1135966         6.09  10.45      14.02       6.96         7.06    NaN  \n",
      "1135967         1.91   6.43       8.86       4.35         4.51    NaN  \n",
      "1135968         4.95   4.93       9.29       0.82         8.47    NaN  \n",
      "1135969         3.97   7.95      10.21       4.29         5.92    NaN  \n",
      "1135970         5.39   5.42       9.63       2.64         6.99    NaN  \n",
      "1135971         9.68   7.64      13.82       3.00        10.82    1.0  \n",
      "1135972         5.45   7.43      10.67       4.36         6.32    NaN  \n",
      "1135973         4.92   3.99       8.03       0.10         7.93    NaN  \n",
      "1135974         2.37   4.12       5.66       2.58         3.08    0.0  \n",
      "1135975         1.52   2.61       3.39       1.88         1.52    NaN  \n",
      "1135976         2.13   2.89       5.66       1.03         4.64    NaN  \n",
      "1135977         1.33   5.56       7.83       4.06         3.77    NaN  \n",
      "1135978         1.36   4.95       6.69       2.64         4.05    NaN  \n",
      "1135979         2.45   6.53       9.35       4.34         5.01    NaN  \n",
      "1135980         4.49   8.45      11.11       5.66         5.46    NaN  \n",
      "1135981         2.92   7.14       8.07       4.82         3.25    0.0  \n",
      "1135982         3.88   6.38       8.41       4.52         3.89    NaN  \n",
      "1135983         1.26   3.67       6.07       2.43         3.64    NaN  \n",
      "\n",
      "[20 rows x 21 columns]\n",
      "Spesifikke kolonner for rad på index 1135974:\n",
      "fips            29213\n",
      "date       2019-01-01\n",
      "PRECTOT          0.02\n",
      "T2M             -0.47\n",
      "Name: 1135974, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "import pandas as pd\n",
    "import pandasql as psql\n",
    "\n",
    "# URL for å laste ned datasettet\n",
    "url = \"https://www.kaggle.com/api/v1/datasets/download/cdminix/us-drought-meteorological-data\"\n",
    "\n",
    "# Send HTTP forespørsel for å laste ned ZIP-filen\n",
    "response = requests.get(url)\n",
    "\n",
    "# Åpne ZIP-filen og sjekk innholdet\n",
    "zip_file = zipfile.ZipFile(io.BytesIO(response.content))\n",
    "print(\"Filer i ZIP:\", zip_file.namelist())\n",
    "\n",
    "# Hent filnavn fra ZIP (den andre filen, index 1)\n",
    "csv_filename = zip_file.namelist()[1]  # Her bruker vi index 1 for å hente den andre filen\n",
    "\n",
    "# Les hele CSV-filen\n",
    "with zip_file.open(csv_filename) as csv_file:\n",
    "    df = pd.read_csv(csv_file)  # Les hele filen\n",
    "\n",
    "# Sjekk om det er duplikate rader i hele DataFrame\n",
    "duplicate_rows = df[df.duplicated()]\n",
    "print(f\"Antall duplikater i DataFrame: {len(duplicate_rows)}\")\n",
    "\n",
    "# Alternativt kan du også fjerne duplikater\n",
    "df_no_duplicates = df.drop_duplicates()\n",
    "print(f\"Antall rader uten duplikater: {len(df_no_duplicates)}\")\n",
    "\n",
    "# Hvis du vil sjekke for duplikater basert på spesifikke kolonner (f.eks. 'fips' og 'date')\n",
    "duplicate_rows_specific = df[df.duplicated(subset=['fips', 'date'])]\n",
    "print(f\"Antall duplikater basert på kolonnene 'fips' og 'date': {len(duplicate_rows_specific)}\")\n",
    "\n",
    "# Bruk SQL for å finne duplikater basert på kolonnene 'fips' og 'date'\n",
    "query = \"\"\"\n",
    "SELECT fips, date, COUNT(*) \n",
    "FROM df \n",
    "GROUP BY fips, date \n",
    "HAVING COUNT(*) > 1\n",
    "\"\"\"\n",
    "duplicate_sql = psql.sqldf(query, locals())\n",
    "print(\"Duplikate rader funnet via SQL:\\n\", duplicate_sql)\n",
    "\n",
    "# Fjerne duplikater\n",
    "df_no_duplicates = df.drop_duplicates()\n",
    "\n",
    "# Kontroller hvor mange rader det er etter at duplikater er fjernet\n",
    "print(f\"Antall rader etter fjerning av duplikater: {len(df_no_duplicates)}\")\n",
    "\n",
    "# Velg en tilfeldig rad fra datasettet\n",
    "random_row = df.sample(n=1)\n",
    "print(\"En tilfeldig rad fra datasettet:\")\n",
    "print(random_row)\n",
    "\n",
    "# Velg en rad ved index (for eksempel den 100,000. raden)\n",
    "index = 100000  # Erstatt med ønsket index\n",
    "specific_row = df.iloc[index]\n",
    "print(f\"Rad på index {index}:\")\n",
    "print(specific_row)\n",
    "\n",
    "# Velg den midterste raden\n",
    "mid_index = len(df) // 2\n",
    "mid_row = df.iloc[mid_index]\n",
    "print(f\"Rad nær midten av datasettet (index {mid_index}):\")\n",
    "print(mid_row)\n",
    "\n",
    "# Velg flere rader rundt midten (10 rader før og etter)\n",
    "rows_around_mid = df.iloc[mid_index-10:mid_index+10]\n",
    "print(\"Rader rundt midten av datasettet:\")\n",
    "print(rows_around_mid)\n",
    "\n",
    "# Velg verdiene fra spesifikke kolonner for en bestemt rad\n",
    "selected_columns = ['fips', 'date', 'PRECTOT', 'T2M']  # Bytt ut med ønskede kolonner\n",
    "specific_row_columns = df.loc[mid_index, selected_columns]\n",
    "print(f\"Spesifikke kolonner for rad på index {mid_index}:\")\n",
    "print(specific_row_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filer i ZIP: ['soil_data.csv', 'test_timeseries/test_timeseries.csv', 'train_timeseries/train_timeseries.csv', 'validation_timeseries/validation_timeseries.csv']\n",
      "Unike fips-koder: [1001 1003 1005 1007 1009 1011 1013 1015 1017 1019 1021 1023 1025 1027\n",
      " 1029 1031 1033 1035 1037 1039]\n",
      "Antall rader etter filtrering: 18630\n",
      "De første radene i det filtrerte datasettet:\n",
      "   fips        date  PRECTOT      PS   QV2M    T2M  T2MDEW  T2MWET  T2M_MAX  \\\n",
      "0  1001  2000-01-01     0.22  100.51   9.65  14.74   13.51   13.51    20.96   \n",
      "1  1001  2000-01-02     0.20  100.55  10.42  16.69   14.71   14.71    22.80   \n",
      "2  1001  2000-01-03     3.65  100.15  11.76  18.49   16.52   16.52    22.73   \n",
      "3  1001  2000-01-04    15.95  100.29   6.42  11.40    6.09    6.10    18.09   \n",
      "4  1001  2000-01-05     0.00  101.15   2.95   3.86   -3.29   -3.20    10.82   \n",
      "\n",
      "   T2M_MIN  ...     TS  WS10M  WS10M_MAX  WS10M_MIN  WS10M_RANGE  WS50M  \\\n",
      "0    11.46  ...  14.65   2.20       2.94       1.49         1.46   4.85   \n",
      "1    12.61  ...  16.60   2.52       3.43       1.83         1.60   5.33   \n",
      "2    15.32  ...  18.41   4.03       5.33       2.66         2.67   7.53   \n",
      "3     2.16  ...  11.31   3.84       5.67       2.08         3.59   6.73   \n",
      "4    -2.66  ...   2.65   1.60       2.50       0.52         1.98   2.94   \n",
      "\n",
      "   WS50M_MAX  WS50M_MIN  WS50M_RANGE  score  \n",
      "0       6.04       3.23         2.81    NaN  \n",
      "1       6.13       3.72         2.41    NaN  \n",
      "2       9.52       5.87         3.66    NaN  \n",
      "3       9.31       3.74         5.58    1.0  \n",
      "4       4.85       0.65         4.19    NaN  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "import pandas as pd\n",
    "\n",
    "# URL for å laste ned datasettet\n",
    "url = \"https://www.kaggle.com/api/v1/datasets/download/cdminix/us-drought-meteorological-data\"\n",
    "\n",
    "# Send HTTP forespørsel for å laste ned ZIP-filen\n",
    "response = requests.get(url)\n",
    "\n",
    "# Åpne ZIP-filen og sjekk innholdet\n",
    "zip_file = zipfile.ZipFile(io.BytesIO(response.content))\n",
    "print(\"Filer i ZIP:\", zip_file.namelist())\n",
    "\n",
    "# Hent filnavn fra ZIP (den andre filen, index 2)\n",
    "csv_filename = zip_file.namelist()[2]  # Her bruker vi index 2 for å hente den andre filen\n",
    "\n",
    "# Les hele CSV-filen\n",
    "with zip_file.open(csv_filename) as csv_file:\n",
    "    df = pd.read_csv(csv_file)  # Les hele filen\n",
    "\n",
    "# Skriv ut unike fips-koder for å få en ide om hva som finnes i datasettet\n",
    "unique_fips = df['fips'].unique()\n",
    "print(f\"Unike fips-koder: {unique_fips[:20]}\")  # Vist bare de første 20 unike fips-kodene\n",
    "\n",
    "# Velg ut 2-3 fips-koder som du ønsker å analysere\n",
    "selected_fips = [1001, 1003, 1005]  # Eksempler på fips-koder (endrer du etter behov)\n",
    "\n",
    "# Filtrer datasettet for de valgte fips-kodene\n",
    "filtered_df = df[df['fips'].isin(selected_fips)]\n",
    "\n",
    "# Sjekk antall rader etter filtrering\n",
    "print(f\"Antall rader etter filtrering: {len(filtered_df)}\")\n",
    "\n",
    "# Lagre det filtrerte datasettet til en ny CSV-fil\n",
    "filtered_df.to_csv('filtered_data.csv', index=False)\n",
    "\n",
    "# Skriv ut de første radene i det nye datasettet\n",
    "print(\"De første radene i det filtrerte datasettet:\")\n",
    "print(filtered_df.head())\n",
    "\n",
    "# RIKTIG KODE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
