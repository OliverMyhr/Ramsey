{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filer i ZIP: ['soil_data.csv', 'test_timeseries/test_timeseries.csv', 'train_timeseries/train_timeseries.csv', 'validation_timeseries/validation_timeseries.csv']\n",
      "Kolonnenavn: Index(['fips', 'date', 'PRECTOT', 'PS', 'QV2M', 'T2M', 'T2MDEW', 'T2MWET',\n",
      "       'T2M_MAX', 'T2M_MIN', 'T2M_RANGE', 'TS', 'WS10M', 'WS10M_MAX',\n",
      "       'WS10M_MIN', 'WS10M_RANGE', 'WS50M', 'WS50M_MAX', 'WS50M_MIN',\n",
      "       'WS50M_RANGE', 'score'],\n",
      "      dtype='object')\n",
      "Antall rader: 0\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://www.kaggle.com/api/v1/datasets/download/cdminix/us-drought-meteorological-data\"\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "zip_file = zipfile.ZipFile(io.BytesIO(response.content))\n",
    "\n",
    "print(\"Filer i ZIP:\", zip_file.namelist())\n",
    "\n",
    "csv_filename = zip_file.namelist()[1]  \n",
    "\n",
    "# Hent ut bare info om dataene uten å laste hele filen\n",
    "with zip_file.open(csv_filename) as csv_file:\n",
    "    # Bruk pandas read_csv med parameteren `nrows` for å hente kun en liten del\n",
    "    df = pd.read_csv(csv_file, nrows=0)  # Henter kun headeren\n",
    "    \n",
    "# Vis kolonnenavn og antall rader\n",
    "print(\"Kolonnenavn:\", df.columns)\n",
    "print(\"Antall rader:\", len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filer i ZIP: ['soil_data.csv', 'test_timeseries/test_timeseries.csv', 'train_timeseries/train_timeseries.csv', 'validation_timeseries/validation_timeseries.csv']\n",
      "Kolonner: Index(['fips', 'date', 'PRECTOT', 'PS', 'QV2M', 'T2M', 'T2MDEW', 'T2MWET',\n",
      "       'T2M_MAX', 'T2M_MIN', 'T2M_RANGE', 'TS', 'WS10M', 'WS10M_MAX',\n",
      "       'WS10M_MIN', 'WS10M_RANGE', 'WS50M', 'WS50M_MAX', 'WS50M_MIN',\n",
      "       'WS50M_RANGE', 'score'],\n",
      "      dtype='object')\n",
      "Antall rader: 2271948\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "import pandas as pd\n",
    "import pandasql as psql\n",
    "\n",
    "url = \"https://www.kaggle.com/api/v1/datasets/download/cdminix/us-drought-meteorological-data\"\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "zip_file = zipfile.ZipFile(io.BytesIO(response.content))\n",
    "\n",
    "print(\"Filer i ZIP:\", zip_file.namelist())\n",
    "\n",
    "csv_filename = zip_file.namelist()[1]  \n",
    "\n",
    "# Les inn CSV-filen som vanlig\n",
    "with zip_file.open(csv_filename) as csv_file:\n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "# Bruk pandasql for SQL-lignende spørringer\n",
    "query = \"SELECT * FROM df LIMIT 0\"  # Henter kun headeren, ingen data\n",
    "metadata = psql.sqldf(query, locals())\n",
    "\n",
    "# Skriv ut kolonner og antall rader\n",
    "print(\"Kolonner:\", metadata.columns)\n",
    "print(\"Antall rader:\", len(df))\n",
    "\n",
    "#Korrekt kode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'train_timeseries.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m csv_filename = \u001b[33m'\u001b[39m\u001b[33mtrain_timeseries.csv\u001b[39m\u001b[33m'\u001b[39m  \u001b[38;5;66;03m# Lokasjonen til din fil på datamaskinen\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Les hele CSV-filen\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_filename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Bruk pandasql for SQL-lignende spørringer\u001b[39;00m\n\u001b[32m     11\u001b[39m query = \u001b[33m\"\u001b[39m\u001b[33mSELECT * FROM df LIMIT 0\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# Henter kun headeren, ingen data\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Adam\\Anvendt Programmering\\Ramsey_Del1\\Ramsey-1\\proj_environment\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Adam\\Anvendt Programmering\\Ramsey_Del1\\Ramsey-1\\proj_environment\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Adam\\Anvendt Programmering\\Ramsey_Del1\\Ramsey-1\\proj_environment\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Adam\\Anvendt Programmering\\Ramsey_Del1\\Ramsey-1\\proj_environment\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Adam\\Anvendt Programmering\\Ramsey_Del1\\Ramsey-1\\proj_environment\\.venv\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'train_timeseries.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pandasql as psql\n",
    "\n",
    "# Les CSV-filen direkte fra din lokale fil\n",
    "csv_filename = 'train_timeseries.csv'  # Lokasjonen til din fil på datamaskinen\n",
    "\n",
    "# Les hele CSV-filen\n",
    "df = pd.read_csv(csv_filename)\n",
    "\n",
    "# Bruk pandasql for SQL-lignende spørringer\n",
    "query = \"SELECT * FROM df LIMIT 0\"  # Henter kun headeren, ingen data\n",
    "metadata = psql.sqldf(query, locals())\n",
    "\n",
    "# Skriv ut kolonner og antall rader\n",
    "print(\"Kolonner:\", metadata.columns)\n",
    "print(\"Antall rader:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filer i ZIP: ['soil_data.csv', 'test_timeseries/test_timeseries.csv', 'train_timeseries/train_timeseries.csv', 'validation_timeseries/validation_timeseries.csv']\n",
      "   fips        date  PRECTOT      PS  QV2M    T2M  T2MDEW  T2MWET  T2M_MAX  \\\n",
      "0  1001  2019-01-01     2.25  100.51  9.69  14.71   13.55   13.52    17.38   \n",
      "1  1001  2019-01-02     4.94  100.48  8.65  13.05   11.83   11.74    17.76   \n",
      "2  1001  2019-01-03    20.74  100.03  8.59  12.12   11.67   11.67    13.74   \n",
      "3  1001  2019-01-04    16.17   99.47  7.93  11.80   10.38    9.59    18.19   \n",
      "4  1001  2019-01-05     0.01  100.39  5.32   7.91    4.73    4.71    14.37   \n",
      "\n",
      "   T2M_MIN  ...     TS  WS10M  WS10M_MAX  WS10M_MIN  WS10M_RANGE  WS50M  \\\n",
      "0    10.92  ...  14.63   1.20       1.50       0.79         0.71   2.74   \n",
      "1     9.54  ...  13.06   1.02       1.35       0.32         1.03   2.13   \n",
      "2    10.44  ...  12.12   1.83       4.23       0.34         3.88   3.41   \n",
      "3     5.44  ...  11.72   3.75       5.25       2.34         2.91   6.78   \n",
      "4     3.68  ...   7.75   2.32       2.90       1.69         1.21   4.42   \n",
      "\n",
      "   WS50M_MAX  WS50M_MIN  WS50M_RANGE  score  \n",
      "0       4.01       1.23         2.78    0.0  \n",
      "1       3.37       0.56         2.81    NaN  \n",
      "2       7.49       0.72         6.77    NaN  \n",
      "3       9.61       4.90         4.71    NaN  \n",
      "4       5.87       3.15         2.72    NaN  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "Kolonner: Index(['fips', 'date', 'PRECTOT', 'PS', 'QV2M', 'T2M', 'T2MDEW', 'T2MWET',\n",
      "       'T2M_MAX', 'T2M_MIN', 'T2M_RANGE', 'TS', 'WS10M', 'WS10M_MAX',\n",
      "       'WS10M_MIN', 'WS10M_RANGE', 'WS50M', 'WS50M_MAX', 'WS50M_MIN',\n",
      "       'WS50M_RANGE', 'score'],\n",
      "      dtype='object')\n",
      "Antall rader: 2271948\n",
      "Forventet antall rader: 5840\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "import pandas as pd\n",
    "import pandasql as psql\n",
    "\n",
    "url = \"https://www.kaggle.com/api/v1/datasets/download/cdminix/us-drought-meteorological-data\"\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "# Åpne ZIP-filen og sjekk innholdet\n",
    "zip_file = zipfile.ZipFile(io.BytesIO(response.content))\n",
    "print(\"Filer i ZIP:\", zip_file.namelist())\n",
    "\n",
    "# Hent filnavn fra ZIP (antar at det er CSV filen på den andre indeksen)\n",
    "csv_filename = zip_file.namelist()[1]  \n",
    "\n",
    "# Sjekk de første radene for å få oversikt over strukturen\n",
    "with zip_file.open(csv_filename) as csv_file:\n",
    "    df_preview = pd.read_csv(csv_file, nrows=5)  # Kun de første 5 radene for å inspisere\n",
    "print(df_preview)\n",
    "\n",
    "# Hvis du har en veldig stor fil, kan du bruke chunksize for å lese den i biter\n",
    "# Bestem hvilke kolonner og datatyper du trenger\n",
    "dtype = {\n",
    "    'column1': 'str',  # Endre til relevante kolonner og datatyper\n",
    "    'column2': 'float',\n",
    "    # ... spesifiser flere kolonner etter behov\n",
    "}\n",
    "\n",
    "# Bruk chunksize for å lese inn data i biter\n",
    "chunk_size = 100000  # Juster etter hva som passer for minnet ditt\n",
    "chunks = []\n",
    "with zip_file.open(csv_filename) as csv_file:\n",
    "    for chunk in pd.read_csv(csv_file, chunksize=chunk_size, dtype=dtype):\n",
    "        chunks.append(chunk)\n",
    "\n",
    "# Slå sammen alle bitene\n",
    "df = pd.concat(chunks, axis=0)\n",
    "\n",
    "# Bruk pandasql for SQL-lignende spørringer\n",
    "query = \"SELECT * FROM df LIMIT 0\"  # Henter kun headeren\n",
    "metadata = psql.sqldf(query, locals())\n",
    "\n",
    "# Skriv ut kolonner og antall rader\n",
    "print(\"Kolonner:\", metadata.columns)\n",
    "print(\"Antall rader:\", len(df))\n",
    "\n",
    "# Hvis du forventer 16*365 rader (16 år, 365 dager per år), kan du kontrollere om antall rader er korrekt\n",
    "expected_rows = 16 * 365\n",
    "print(f\"Forventet antall rader: {expected_rows}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filer i ZIP: ['soil_data.csv', 'test_timeseries/test_timeseries.csv', 'train_timeseries/train_timeseries.csv', 'validation_timeseries/validation_timeseries.csv']\n",
      "Første 5 rader:    fips        date  PRECTOT      PS  QV2M    T2M  T2MDEW  T2MWET  T2M_MAX  \\\n",
      "0  1001  2019-01-01     2.25  100.51  9.69  14.71   13.55   13.52    17.38   \n",
      "1  1001  2019-01-02     4.94  100.48  8.65  13.05   11.83   11.74    17.76   \n",
      "2  1001  2019-01-03    20.74  100.03  8.59  12.12   11.67   11.67    13.74   \n",
      "3  1001  2019-01-04    16.17   99.47  7.93  11.80   10.38    9.59    18.19   \n",
      "4  1001  2019-01-05     0.01  100.39  5.32   7.91    4.73    4.71    14.37   \n",
      "\n",
      "   T2M_MIN  ...     TS  WS10M  WS10M_MAX  WS10M_MIN  WS10M_RANGE  WS50M  \\\n",
      "0    10.92  ...  14.63   1.20       1.50       0.79         0.71   2.74   \n",
      "1     9.54  ...  13.06   1.02       1.35       0.32         1.03   2.13   \n",
      "2    10.44  ...  12.12   1.83       4.23       0.34         3.88   3.41   \n",
      "3     5.44  ...  11.72   3.75       5.25       2.34         2.91   6.78   \n",
      "4     3.68  ...   7.75   2.32       2.90       1.69         1.21   4.42   \n",
      "\n",
      "   WS50M_MAX  WS50M_MIN  WS50M_RANGE  score  \n",
      "0       4.01       1.23         2.78    0.0  \n",
      "1       3.37       0.56         2.81    NaN  \n",
      "2       7.49       0.72         6.77    NaN  \n",
      "3       9.61       4.90         4.71    NaN  \n",
      "4       5.87       3.15         2.72    NaN  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "Siste 5 rader:    1001  2019-01-05  0.01  100.39  5.32   7.91   4.73   4.71  14.37  3.68  \\\n",
      "0  1001  2019-01-06  0.00  100.69  5.76  10.26   5.94   5.82  18.38  2.31   \n",
      "1  1001  2019-01-07  0.01  100.65  7.03  11.03   8.78   8.67  18.42  5.03   \n",
      "2  1001  2019-01-08  0.05  100.57  8.75  13.15  12.01  11.98  20.04  9.36   \n",
      "3  1001  2019-01-09  0.00  100.90  4.55   6.51   2.60   2.36  11.30  1.52   \n",
      "4  1001  2019-01-10  0.00  100.92  3.30   2.53  -1.82  -1.83   9.17 -1.96   \n",
      "\n",
      "   ...   7.75  2.32   2.9  1.69  1.21  4.42  5.87  3.15  2.72  Unnamed: 20  \n",
      "0  ...   8.57  1.37  2.04  0.22  1.82  2.36  4.93  0.35  4.58          NaN  \n",
      "1  ...  10.82  1.94  2.53  1.28  1.25  4.30  5.93  1.86  4.06          NaN  \n",
      "2  ...  13.05  2.33  3.40  1.68  1.72  5.13  6.51  3.67  2.85          0.0  \n",
      "3  ...   6.42  3.03  4.63  2.09  2.54  5.85  7.35  3.99  3.36          NaN  \n",
      "4  ...   2.56  2.46  3.24  1.96  1.28  4.95  6.31  4.28  2.03          NaN  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "read_csv() got an unexpected keyword argument 'error_bad_lines'. Did you mean 'on_bad_lines'?",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 29\u001b[39m\n\u001b[32m     25\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mSiste 5 rader:\u001b[39m\u001b[33m\"\u001b[39m, df_tail)\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m zip_file.open(csv_filename) \u001b[38;5;28;01mas\u001b[39;00m csv_file:\n\u001b[32m     28\u001b[39m     \u001b[38;5;66;03m# Les inn filen med ekstra parametere for å håndtere feil og tomme linjer\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m     df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_blank_lines\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_bad_lines\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     30\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAntall rader etter behandling: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     32\u001b[39m chunk_size = \u001b[32m100000\u001b[39m  \u001b[38;5;66;03m# Juster etter hva som passer for minnet ditt\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: read_csv() got an unexpected keyword argument 'error_bad_lines'. Did you mean 'on_bad_lines'?"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://www.kaggle.com/api/v1/datasets/download/cdminix/us-drought-meteorological-data\"\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "# Åpne ZIP-filen og sjekk innholdet\n",
    "zip_file = zipfile.ZipFile(io.BytesIO(response.content))\n",
    "print(\"Filer i ZIP:\", zip_file.namelist())\n",
    "\n",
    "# Hent filnavn fra ZIP (antar at det er CSV filen på den andre indeksen)\n",
    "csv_filename = zip_file.namelist()[1]\n",
    "\n",
    "# Sjekk de første og siste radene for å inspisere innholdet\n",
    "with zip_file.open(csv_filename) as csv_file:\n",
    "    df_preview = pd.read_csv(csv_file, nrows=5)  # Første 5 rader\n",
    "    print(\"Første 5 rader:\", df_preview)\n",
    "\n",
    "# Nå sjekker vi de siste radene for å finne ut om det er noen tomme eller uvanlige linjer\n",
    "with zip_file.open(csv_filename) as csv_file:\n",
    "    df_tail = pd.read_csv(csv_file, skiprows=lambda x: x < 5, nrows=5)  # Siste 5 rader\n",
    "    print(\"Siste 5 rader:\", df_tail)\n",
    "\n",
    "with zip_file.open(csv_filename) as csv_file:\n",
    "    # Les inn filen med ekstra parametere for å håndtere feil og tomme linjer\n",
    "    df = pd.read_csv(csv_file, skip_blank_lines=True, error_bad_lines=False)\n",
    "    print(f\"Antall rader etter behandling: {len(df)}\")\n",
    "\n",
    "chunk_size = 100000  # Juster etter hva som passer for minnet ditt\n",
    "chunks = []\n",
    "with zip_file.open(csv_filename) as csv_file:\n",
    "    for chunk in pd.read_csv(csv_file, chunksize=chunk_size, skip_blank_lines=True, error_bad_lines=False):\n",
    "        chunks.append(chunk)\n",
    "\n",
    "# Slå sammen alle bitene\n",
    "df = pd.concat(chunks, axis=0)\n",
    "print(f\"Antall rader etter behandling i biter: {len(df)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
